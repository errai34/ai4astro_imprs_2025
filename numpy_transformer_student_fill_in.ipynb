{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖  Mini-Transformer with NumPy: A Hands-On Tutorial\n",
    "\n",
    "Author: Ioana Ciucă + Claude Opus 4.1 \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this tutorial, you will:\n",
    "- Understand the fundamental building blocks of transformers\n",
    "- Implement a transformer with a single attention head from tokenization -> embedding + positional encoding -> attention head -> output logits.\n",
    "- Visualize how attention works\n",
    "\n",
    "Through this tutorial, you will implement the folllowing:\n",
    "#### 1. **Tokenizer** \n",
    "Transform text into numbers that the model can process\n",
    "\n",
    "#### 2. **Embeddings & Positional Encoding** \n",
    "- Token embeddings: Learn representations for each token\n",
    "- Sinusoidal positional encoding: Tell the model about word order\n",
    "\n",
    "#### 3. **Single-Head Causal Self-Attention** \n",
    "The heart of the transformer:\n",
    "- **Query (Q)**, **Key (K)**, **Value (V)** projections\n",
    "- Attention scores with causal masking\n",
    "- Softmax normalization\n",
    "- Simple residual connections\n",
    "\n",
    "#### 4. **Output Layer** \n",
    "Linear transformation to predict the next token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8babd4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Tokenizer: From Text to Numbers\n",
    "\n",
    "Before a neural network can understand text, we need to convert words into numbers. This process, called **tokenization**, is the foundation of every language model, from BERT to GPT.\n",
    "\n",
    "### How Our Simple Tokenizer Works\n",
    "\n",
    "#### 1. **Splitting Text into Tokens** \n",
    "We separate words and punctuation, treating each as its own unit:\n",
    "- `\"Hello, world!\"` → `[\"Hello\", \",\", \"world\", \"!\"]`\n",
    "- Punctuation becomes separate tokens (important for understanding sentence structure!)\n",
    "\n",
    "#### 2. **Building a Vocabulary**\n",
    "We scan all training texts and create a mapping:\n",
    "```python\n",
    "token_to_id = {\n",
    "    \"<pad>\": 0,   # Padding for batch processing\n",
    "    \"<bos>\": 1,   # Beginning of sequence\n",
    "    \"<eos>\": 2,   # End of sequence  \n",
    "    \"<unk>\": 3,   # Unknown/rare words\n",
    "    \"the\": 4,\n",
    "    \"hello\": 5,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "Tokens are ordered by frequency, with common words geting lower IDs.\n",
    "\n",
    "#### 3. **Encoding: Text → Numbers**\n",
    "Convert any text into a sequence of IDs:\n",
    "- `\"Hello world\"` → `[1, 5, 87, 2]` (with BOS/EOS tokens)\n",
    "- Unknown words map to `<unk>` token\n",
    "\n",
    "#### 4. **Decoding: Numbers → Text**\n",
    "Reverse the process to see what the model \"sees\":\n",
    "- `[5, 87]` → `\"hello world\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(text):\n",
    "    \"\"\"Split text into words and punctuation tokens\"\"\"\n",
    "    # Step 1: Mark punctuation with spaces\n",
    "    punct = '.,!?;:\"()[]{}'\n",
    "    text_with_spaces = \"\"\n",
    "\n",
    "    for character in text:\n",
    "        if character in punct:\n",
    "            # Add spaces around punctuation\n",
    "            text_with_spaces += \" \" + character + \" \"\n",
    "        else:\n",
    "            text_with_spaces += character\n",
    "\n",
    "    # Step 2: Split by spaces to get tokens\n",
    "    tokens = text_with_spaces.split()\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(texts):\n",
    "    \"\"\"Build vocabulary from training texts\"\"\"\n",
    "    # Start with special tokens\n",
    "    token_to_id = {}\n",
    "    token_to_id[\"<pad>\"] = 0  # for padding sequences\n",
    "    token_to_id[\"<bos>\"] = 1  # beginning of sequence\n",
    "    token_to_id[\"<eos>\"] = 2  # end of sequence\n",
    "    token_to_id[\"<unk>\"] = 3  # unknown words\n",
    "\n",
    "    # Step 1: Count how often each token appears\n",
    "    token_counts = {}\n",
    "    for text in texts:\n",
    "        text_lower = text.lower()\n",
    "        tokens = split_tokens(text_lower)\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "\n",
    "    # Step 2: Sort tokens by frequency (most common first)\n",
    "    sorted_tokens = []\n",
    "    for token, count in token_counts.items():\n",
    "        sorted_tokens.append((token, count))\n",
    "    sorted_tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Step 3: Assign IDs to tokens\n",
    "    next_id = 4  # Start after special tokens\n",
    "    for token, count in sorted_tokens:\n",
    "        if token not in token_to_id:\n",
    "            token_to_id[token] = next_id\n",
    "            next_id += 1\n",
    "\n",
    "    # Step 4: Create reverse mapping (ID to token)\n",
    "    id_to_token = {}\n",
    "    for token, token_id in token_to_id.items():\n",
    "        id_to_token[token_id] = token\n",
    "\n",
    "    return token_to_id, id_to_token\n",
    "\n",
    "def encode(text, token_to_id, add_bos=False, add_eos=False):\n",
    "    \"\"\"Convert text to list of token IDs\"\"\"\n",
    "    # Convert to lowercase and split into tokens\n",
    "    text_lower = text.lower()\n",
    "    tokens = split_tokens(text_lower)\n",
    "\n",
    "    # Convert each token to its ID\n",
    "    ids = []\n",
    "    for token in tokens:\n",
    "        if token in token_to_id:\n",
    "            ids.append(token_to_id[token])\n",
    "        else:\n",
    "            # Use <unk> for unknown tokens\n",
    "            ids.append(token_to_id[\"<unk>\"])\n",
    "\n",
    "    # Add special tokens if requested\n",
    "    if add_bos:\n",
    "        ids = [token_to_id[\"<bos>\"]] + ids\n",
    "    if add_eos:\n",
    "        ids = ids + [token_to_id[\"<eos>\"]]\n",
    "\n",
    "    return np.array(ids, dtype=np.int64)\n",
    "\n",
    "def decode(ids, id_to_token):\n",
    "    \"\"\"Convert list of token IDs back to text\"\"\"\n",
    "    tokens = []\n",
    "\n",
    "    for token_id in ids:\n",
    "        # Convert ID to token\n",
    "        if token_id in id_to_token:\n",
    "            token = id_to_token[token_id]\n",
    "\n",
    "            # Skip special tokens in output\n",
    "            if token not in [\"<bos>\", \"<eos>\", \"<pad>\"]:\n",
    "                tokens.append(token)\n",
    "        else:\n",
    "            tokens.append(\"<unk>\")\n",
    "\n",
    "    # Join tokens with spaces\n",
    "    text = \" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8d489",
   "metadata": {},
   "source": [
    "### Try it out :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14fff339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10\n",
      "First 10 tokens: [('<pad>', 0), ('<bos>', 1), ('<eos>', 2), ('<unk>', 3), ('hello', 4), ('world', 5), ('.', 6), ('!', 7), ('there', 8), ('peace', 9)]\n",
      "\n",
      "Original: Hello, world!\n",
      "Token IDs: [1 4 3 5 7 2]\n",
      "Decoded: hello <unk> world !\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "texts = [\"Hello world!\", \"Hello there.\", \"World peace.\"]\n",
    "\n",
    "# Build vocabulary\n",
    "token_to_id, id_to_token = build_vocab(texts)\n",
    "print(f\"Vocabulary size: {len(token_to_id)}\")\n",
    "print(f\"First 10 tokens: {list(token_to_id.items())[:10]}\")\n",
    "\n",
    "# Encode a sentence\n",
    "sentence = \"Hello, world!\"\n",
    "ids = encode(sentence, token_to_id, add_bos=True, add_eos=True)\n",
    "print(f\"\\nOriginal: {sentence}\")\n",
    "print(f\"Token IDs: {ids}\")\n",
    "\n",
    "# Decode back\n",
    "decoded = decode(ids, id_to_token)\n",
    "print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can build and understand a tiny astronomy-flavored text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 36\n",
      "First 20 tokens: [('<pad>', 0), ('<bos>', 1), ('<eos>', 2), ('<unk>', 3), ('.', 4), ('a', 5), ('is', 6), ('b', 7), ('g', 8), ('m', 9), ('type', 10), ('star', 11), ('o', 12), ('f', 13), ('k', 14), ('the', 15), ('an', 16), ('mercury', 17), ('venus', 18), ('earth', 19)]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"O B A F G K M O B A F G K M O B A F G K M .\",\n",
    "    \"Mercury Venus Earth Mars Jupiter Saturn Uranus Neptune .\",\n",
    "    \"The Sun is a G type star in the Milky Way .\",\n",
    "    \"Betelgeuse is an M type star .\",\n",
    "    \"Rigel is a B type star .\",\n",
    "    \"Sirius is an A type star .\",\n",
    "    \"Andromeda is also called M31 .\"\n",
    "]\n",
    "\n",
    "token_to_id, id_to_token =  build_vocab(texts) #TODO: add your code here\n",
    "vocab_size = len(token_to_id)\n",
    "\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(f\"First 20 tokens: {list(token_to_id.items())[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be9e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The Sun is a G type star in the Milky Way.\n",
      "Token IDs: [464, 3825, 318, 257, 402, 2099, 3491, 287, 262, 34822, 6378, 13]\n",
      "Number of tokens: 12\n",
      "\n",
      "Token breakdown:\n",
      "    464 → 'The'\n",
      "   3825 → ' Sun'\n",
      "    318 → ' is'\n",
      "    257 → ' a'\n",
      "    402 → ' G'\n",
      "   2099 → ' type'\n",
      "   3491 → ' star'\n",
      "    287 → ' in'\n",
      "    262 → ' the'\n",
      "  34822 → ' Milky'\n",
      "   6378 → ' Way'\n",
      "     13 → '.'\n",
      "\n",
      "Character tokenization would use 42 tokens\n",
      "GPT-2 tokenization uses 12 tokens\n",
      "Efficiency gain: 3.5x\n",
      "How GPT-2 splits words:\n",
      "  'unbelievable' → ['un', 'bel', 'iev', 'able']\n",
      "  'artificial' → ['art', 'ificial']\n",
      "  'consciousness' → ['conscious', 'ness']\n",
      "  'Mars' → ['Mars']\n",
      "  'M31' → ['M', '31']\n"
     ]
    }
   ],
   "source": [
    "# Install: pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "def demo_real_tokenization():\n",
    "    \"\"\"Show how GPT actually tokenizes text\"\"\"\n",
    "\n",
    "    # Get GPT-2's tokenizer\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Example text\n",
    "    text = \"The Sun is a G type star in the Milky Way.\"\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = enc.encode(text)\n",
    "\n",
    "    print(\"Original text:\", text)\n",
    "    print(f\"Token IDs: {tokens}\")\n",
    "    print(f\"Number of tokens: {len(tokens)}\")\n",
    "\n",
    "    # Show each token\n",
    "    print(\"\\nToken breakdown:\")\n",
    "    for token_id in tokens:\n",
    "        token_str = enc.decode([token_id])\n",
    "        print(f\"  {token_id:5d} → '{token_str}'\")\n",
    "\n",
    "    # Compare with character tokenization\n",
    "    char_tokens = list(text)\n",
    "    print(f\"\\nCharacter tokenization would use {len(char_tokens)} tokens\")\n",
    "    print(f\"GPT-2 tokenization uses {len(tokens)} tokens\")\n",
    "    print(f\"Efficiency gain: {len(char_tokens)/len(tokens):.1f}x\")\n",
    "\n",
    "    # Show subword tokenization\n",
    "    interesting_words = [\n",
    "        \"unbelievable\",\n",
    "        \"artificial\",\n",
    "        \"consciousness\",\n",
    "        \"Mars\",\n",
    "        \"M31\"\n",
    "    ]\n",
    "\n",
    "    print(\"How GPT-2 splits words:\")\n",
    "    for word in interesting_words:\n",
    "        tokens = enc.encode(word)\n",
    "        pieces = [enc.decode([t]) for t in tokens]\n",
    "        print(f\"  '{word}' → {pieces}\")\n",
    "\n",
    "# Run the demo\n",
    "demo_real_tokenization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4add014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Simple Tokenizer:\n",
      "Vocabulary size: 36\n",
      "Tokens for 'The Sun': [15 25]\n",
      "How GPT-2 Would Tokenize:\n",
      "Vocabulary size: 50257\n",
      "Tokens for 'The Sun': [464, 3825]\n"
     ]
    }
   ],
   "source": [
    "print(\"Our Simple Tokenizer:\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Tokens for 'The Sun': {encode('The Sun', token_to_id)}\")\n",
    "\n",
    "print(\"How GPT-2 Would Tokenize:\")\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "print(f\"Vocabulary size: {enc.n_vocab}\")  # 50,257!\n",
    "print(f\"Tokens for 'The Sun': {enc.encode('The Sun')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47025b8a",
   "metadata": {},
   "source": [
    "## Q1: Exploring Your Tokenizer\n",
    "\n",
    "You've built a tokenizer using this astronomy corpus:\n",
    "\n",
    "```python\n",
    "texts = [\n",
    "    \"O B A F G K M O B A F G K M O B A F G K M .\",\n",
    "    \"Mercury Venus Earth Mars Jupiter Saturn Uranus Neptune .\",\n",
    "    \"The Sun is a G type star in the Milky Way .\",\n",
    "    \"Betelgeuse is an M type star .\",\n",
    "    \"Rigel is a B type star .\",\n",
    "    \"Sirius is an A type star .\",\n",
    "    \"Andromeda is also called M31 .\"\n",
    "]\n",
    "```\n",
    "\n",
    "1. **Without running code**, predict which regular word (not special token) will have the lowest ID? Why?\n",
    "\n",
    "2. **Encode patterns**: Encode these sentences and answer why the first two sentences produce different results?\n",
    "\n",
    "```python\n",
    "test_sentences = [\n",
    "    \"The Sun .\",\n",
    "    \"the sun .\",\n",
    "    \"Betelgeuse is a star .\",\n",
    "    \"Proxima Centauri is a star .\",\n",
    "    \"A B C D E F G .\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0180807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embeddings + Sinusoidal Position Encoding\n",
    "\n",
    "Remember our tokens `[5, 87, 42]`? These numbers don't mean anything to a neural network yet. We need to convert each token into a **vector**, a list of decimal numbers that can capture meaning.\n",
    "\n",
    "Think of it like this:\n",
    "- Token ID `5` (maybe \"cat\") → `[0.2, -0.1, 0.8, ...]` \n",
    "- Token ID `87` (maybe \"dog\") → `[0.3, -0.2, 0.7, ...]`\n",
    "\n",
    "These vectors can learn that \"cat\" and \"dog\" are similar (both animals) by having similar values!\n",
    "\n",
    "## The Problem with Order\n",
    "\n",
    "Transformers process all tokens at once (unlike RNNs that go step-by-step). But word order matters!\n",
    "- \"The cat ate the mouse\" ≠ \"The mouse ate the cat\" 🐱🐭\n",
    "\n",
    "**Solution:** Add position information to each embedding using **sinusoidal positional encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_embeddings(vocab_size, d_model, scale=0.02, seed=0):\n",
    "    \"\"\"Create random embedding vectors for each token in vocabulary\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    return rng.randn(vocab_size, d_model).astype(np.float32) * scale\n",
    "\n",
    "def sinusoidal_positional_encoding(T, d_model):\n",
    "    \"\"\"Create unique position vectors using sine/cosine waves\"\"\"\n",
    "    pe = np.zeros((T, d_model), dtype=np.float32)\n",
    "\n",
    "    # For each position in the sequence\n",
    "    for pos in range(T):\n",
    "        # For each dimension of the embedding\n",
    "        for i in range(0, d_model, 2):\n",
    "            # Calculate the divisor for this dimension\n",
    "            # This creates different frequencies for different dimensions\n",
    "            divisor = 10000.0 ** (i / d_model)\n",
    "\n",
    "            # Apply sine to even dimensions\n",
    "            pe[pos, i] = np.sin(pos / divisor)\n",
    "\n",
    "            # Apply cosine to odd dimensions (if not last dimension)\n",
    "            if i + 1 < d_model:\n",
    "                pe[pos, i + 1] = np.cos(pos / divisor)\n",
    "\n",
    "    return pe\n",
    "\n",
    "def embed(token_ids, W_E, PE):\n",
    "    \"\"\"Combine token embeddings with positional information\"\"\"\n",
    "    return W_E[token_ids] + PE[:len(token_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5b28e",
   "metadata": {},
   "source": [
    "## Q2: Explore embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15553f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 48\n",
    "vocab_size = len(token_to_id)\n",
    "W_E = init_embeddings(vocab_size, d_model, scale=0.02, seed=42)\n",
    "PE = sinusoidal_positional_encoding(T=100, d_model=d_model)\n",
    "\n",
    "# TODO: Print W_E and PE\n",
    "# print(f\"W_E: {W_E}\")\n",
    "# print(f\"PE shape: {PE}\")\n",
    "\n",
    "# TODO: Print the shapes\n",
    "# print(f\"W_E shape: {W_E.shape} means ...\")\n",
    "# print(f\"PE shape: {PE.shape} means ...\")\n",
    "\n",
    "### 2. Extract Sun's Embedding\n",
    "\n",
    "# TODO: Get the embedding vector for \"sun\"\n",
    "# sun_id = token_to_id[\"sun\"]\n",
    "# sun_embedding = W_E[...]\n",
    "# print(f\"'sun' embedding (first 5 dims): {sun_embedding[:5]}\")\n",
    "\n",
    "### 3. Same Word, Different Positions\n",
    "\n",
    "sentence = \"star type star .\"\n",
    "token_ids = encode(sentence, token_to_id)\n",
    "embedded = embed(token_ids, W_E, PE)\n",
    "\n",
    "# TODO: Compare \"star\" at position 0 vs position 2\n",
    "# print(f\"'star' at position 0: {embedded[0][:5]}\")\n",
    "# print(f\"'star' at position 2: {embedded[2][:5]}\")\n",
    "# print(\"Are they the same?\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0fa4e",
   "metadata": {},
   "source": [
    "## For more info, you can have a more in depth read here.\n",
    "\n",
    "https://alessiodevoto.github.io/LLM-Embedding-Space/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single-Head Attention — Parameters & Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c02286",
   "metadata": {},
   "source": [
    "## What is Softmax?\n",
    "\n",
    "Softmax converts a list of numbers (scores) into probabilities that sum to 1.\n",
    "\n",
    "**Input:** Any list of numbers, like `[2, 5, 1]`  \n",
    "**Output:** Probabilities that sum to 1, like `[0.04, 0.87, 0.09]`\n",
    "\n",
    "For each score $z_i$ in your list:\n",
    "\n",
    "$$\\text{probability}_i = \\frac{e^{z_i}}{\\text{sum of all } e^z}$$\n",
    "\n",
    "### Example\n",
    "Given scores `[2, 5, 1]`:\n",
    "- Calculate: $e^2 \\approx 7.4$, $e^5 \\approx 146.1 $, $e^1 \\approx 2.7$\n",
    "- Sum: $7.4 + 146.1 + 2.7 = 156.2$\n",
    "- Probabilities: $[7.4/156.2, 146.4/156.2, 2.7/156.2] = [0.05, 0.94, 0.02]$\n",
    "\n",
    "The highest score (5) gets the highest probability (94%).\n",
    "\n",
    "### Why Use Softmax?\n",
    "\n",
    "1. **Creates valid probabilities**: All outputs between 0 and 1, sum to 1\n",
    "2. **Preserves order**: Higher scores → higher probabilities\n",
    "3. **Differentiable**: Works well with neural networks\n",
    "\n",
    "\n",
    "### Numerical Stability Trick\n",
    "\n",
    "**Problem:** $e^{1000}$ causes overflow!\n",
    "\n",
    "**Solution:** Subtract the maximum score first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ce4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(x, axis=-1):\n",
    "    \"\"\"\n",
    "    TODO-1: Implement numerically stable softmax along `axis`.\n",
    "    Steps:\n",
    "      1) subtract the row-wise max\n",
    "      2) exponentiate\n",
    "      3) divide by row-wise sum\n",
    "    \"\"\"\n",
    "    # ----- YOUR CODE -----\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    raise NotImplementedError(\"TODO-1: stable_softmax\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51dacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_softmax():\n",
    "    \"\"\"Simple test case for stable_softmax\"\"\"\n",
    "\n",
    "    # Test input: scores for 3 classes\n",
    "    x = np.array([2.0, 5.0, 1.0])\n",
    "\n",
    "    # Run your implementation\n",
    "    probs = stable_softmax(x)\n",
    "\n",
    "    # Check if it sums to 1\n",
    "    assert np.isclose(probs.sum(), 1.0), f\"Probabilities don't sum to 1: {probs.sum()}\"\n",
    "\n",
    "    # Check expected values (approximately)\n",
    "    expected = np.array([0.0466, 0.9362, 0.0172])\n",
    "    assert np.allclose(probs, expected, atol=0.01), f\"Got {probs}, expected ~{expected}\"\n",
    "\n",
    "    print(\"✅ Test passed!\")\n",
    "    print(f\"Input:  {x}\")\n",
    "    print(f\"Output: {probs}\")\n",
    "    print(f\"Sum:    {probs.sum()}\")\n",
    "\n",
    "    return x, probs\n",
    "\n",
    "\n",
    "scores, probs = test_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18c52651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 5. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Try different scores to see how softmax behaves:\n",
      "Example: test_scores = np.array([1, 1, 1]) for uniform distribution\n",
      "Example: test_scores = np.array([10, 0, 0]) for very confident prediction\n"
     ]
    }
   ],
   "source": [
    "# Visualize how softmax transforms scores to probabilities\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Plot 1: Input scores\n",
    "classes = ['Class 0', 'Class 1', 'Class 2']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "print(scores)\n",
    "scores = scores # you can vary here to see how softmax behaves, for example: np.array([1, 1, 1])\n",
    "\n",
    "ax1.bar(classes, scores, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Input Scores (Logits)')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Output probabilities\n",
    "ax2.bar(classes, probs, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_title('After Softmax')\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Softmax Transformation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interactive experiment\n",
    "print(\"\\n Try different scores to see how softmax behaves:\")\n",
    "print(\"Example: test_scores = np.array([1, 1, 1]) for uniform distribution\")\n",
    "print(\"Example: test_scores = np.array([10, 0, 0]) for very confident prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "612d1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(idx, vocab):\n",
    "    v = np.zeros((vocab,), dtype=np.float32);\n",
    "    v[idx] = 1.0\n",
    "    return v\n",
    "\n",
    "def causal_mask(T):\n",
    "    \"\"\"\n",
    "    TODO-2: Return an upper-triangular boolean mask of shape (T, T)\n",
    "    where True means 'mask out' (disallow attending to future).\n",
    "    Hint: np.triu with k=1\n",
    "    \"\"\"\n",
    "    # ----- YOUR CODE -----\n",
    "    # return ...\n",
    "    raise NotImplementedError(\"TODO-2: causal_mask\")\n",
    "\n",
    "def apply_causal_mask(scores, mask):\n",
    "    # mask True → set to large negative so softmax ~ 0\n",
    "    return np.where(mask, -1e9, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_attention_params(d_model, scale=0.02, seed=1):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    W_Q = rng.randn(d_model, d_model).astype(np.float32) * scale\n",
    "    W_K = rng.randn(d_model, d_model).astype(np.float32) * scale\n",
    "    W_V = rng.randn(d_model, d_model).astype(np.float32) * scale\n",
    "    W_O = rng.randn(d_model, d_model).astype(np.float32) * scale\n",
    "    return {\"W_Q\": W_Q, \"W_K\": W_K, \"W_V\": W_V, \"W_O\": W_O}\n",
    "\n",
    "attn_params = init_attention_params(d_model, scale=0.02, seed=1)\n",
    "\n",
    "def attention_forward(X, attn_params):\n",
    "    \"\"\"\n",
    "    TODO-3: Implement scaled dot-product attention (causal).\n",
    "    Given X (T, D) and attn_params, compute:\n",
    "      Q = X @ W_Q\n",
    "      K = X @ W_K\n",
    "      V = X @ W_V\n",
    "      scores = (Q @ K.T) / sqrt(D)\n",
    "      scores_masked = apply_causal_mask(scores, causal_mask(T))\n",
    "      A = softmax(scores_masked, axis=-1)\n",
    "      Z = A @ V\n",
    "      Y = Z @ W_O\n",
    "    Return Y and a cache dict with Q, K, V, A for later use.\n",
    "    \"\"\"\n",
    "    T, D = X.shape\n",
    "    W_Q, W_K, W_V, W_O = attn_params[\"W_Q\"], attn_params[\"W_K\"], attn_params[\"W_V\"], attn_params[\"W_O\"]\n",
    "    # ----- YOUR CODE -----\n",
    "    # Q = ...\n",
    "    # K = ...\n",
    "    # V = ...\n",
    "    # scores = ...\n",
    "    # S = ...\n",
    "    # A = ...\n",
    "    # Z = ...\n",
    "    # Y = ...\n",
    "    raise NotImplementedError(\"TODO-3: attention_forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output Layer + Loss (Cross-Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_output_params(d_model, vocab_size, scale=0.02, seed=2):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    W_out = rng.randn(d_model, vocab_size).astype(np.float32) * scale\n",
    "    b_out = np.zeros((vocab_size,), dtype=np.float32)\n",
    "    return {\"W_out\": W_out, \"b_out\": b_out}\n",
    "\n",
    "out_params = init_output_params(d_model, vocab_size, scale=0.02, seed=2)\n",
    "\n",
    "def logits_forward(H, out_params):\n",
    "    return H @ out_params[\"W_out\"] + out_params[\"b_out\"]\n",
    "\n",
    "def next_token_targets(ids):\n",
    "    return ids[1:]  # predict next token\n",
    "\n",
    "def loss_and_grad_logits(logits, target_ids):\n",
    "    \"\"\"\n",
    "    TODO-4: Cross-entropy loss and gradient wrt logits.\n",
    "\n",
    "    logits: (T, V) - only first T-1 rows have targets\n",
    "    target_ids: (T-1,)\n",
    "\n",
    "    Steps:\n",
    "      1) P = softmax(logits, axis=-1)\n",
    "      2) loss = -mean(log P[0:T-1, target_ids])\n",
    "      3) dlogits = P; subtract 1 at true classes on rows 0..T-2; divide by (T-1)\n",
    "      4) zero the last row's gradient\n",
    "    Return (loss, dlogits)\n",
    "    \"\"\"\n",
    "    T, V = logits.shape\n",
    "    assert len(target_ids) == T-1\n",
    "    # ----- YOUR CODE -----\n",
    "    # P = ...\n",
    "    # loss = ...\n",
    "    # dlogits = ...\n",
    "    raise NotImplementedError(\"TODO-4: loss_and_grad_logits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Attention Map Visualization (nice heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(A, tokens, title=\"Attention (rows=query, cols=key)\"):\n",
    "    \"\"\"\n",
    "    A: (T, T) attention matrix\n",
    "    tokens: list of token strings length T\n",
    "    \"\"\"\n",
    "    T = len(tokens)\n",
    "    fig, ax = plt.subplots(figsize=(max(6, T*0.5), max(4, T*0.4)))\n",
    "    im = ax.imshow(A)  # default colormap\n",
    "    ax.set_xticks(np.arange(T))\n",
    "    ax.set_yticks(np.arange(T))\n",
    "    ax.set_xticklabels(tokens, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(tokens)\n",
    "    ax.set_xlabel(\"Keys (source positions)\")\n",
    "    ax.set_ylabel(\"Queries (destination positions)\")\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    # annotate top-1 per row\n",
    "    for i in range(T):\n",
    "        j = int(np.argmax(A[i]))\n",
    "        ax.text(j, i, f\"{A[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def attention_for_prompt(prompt, params, d_model, token_to_id, id_to_token):\n",
    "    ids = encode(prompt, token_to_id, add_bos=False, add_eos=False)\n",
    "    T = len(ids)\n",
    "    PE = sinusoidal_positional_encoding(T, d_model)\n",
    "    X = embed(ids, params[\"W_E\"], PE)\n",
    "    Y, cache = attention_forward(X, params[\"attn\"])\n",
    "    A = cache[\"A\"]\n",
    "    tokens = [id_to_token[int(i)] for i in ids]\n",
    "    return A, tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A — Interpret an attention map\n",
    "**Task:** Use your trained params to visualize attention on a short astronomy prompt and **explain** what each row is focusing on.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run the cell to compute and plot the map.\n",
    "2. Fill the \"TODO\" to compute the **top-1 attended token** per row and print a readable summary.\n",
    "3. In your own words (markdown cell), write what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"O B A F G K M O B A F\"\n",
    "A, tokens = attention_for_prompt(prompt, params, d_model, token_to_id, id_to_token)\n",
    "plot_attention(A, tokens, title=f\"Attention for: {prompt}\")\n",
    "\n",
    "# TODO-A1: Print the top attended token per row\n",
    "# For each row i, find j = argmax(A[i]) and print tokens[i] attends-to tokens[j] with weight\n",
    "# ----- YOUR CODE -----\n",
    "# for i in range(len(tokens)):\n",
    "#     j = ...\n",
    "#     w = ...\n",
    "#     print(f\"row {i:2d} ({tokens[i]:>6s}) → attends to {tokens[j]:>6s} (w={w:.2f})\")\n",
    "raise NotImplementedError(\"TODO-A1: summarize attention rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B — Compare two prompts\n",
    "**Task:** Compare attention on a spectral snippet versus a planetary snippet.\n",
    "\n",
    "**Instructions:**  \n",
    "1. Plot maps for:\n",
    "   - `\"O B A F G\"`\n",
    "   - `\"Mercury Venus Earth Mars Jupiter\"`  \n",
    "2. Describe whether attention prefers near neighbors (`i-1`) or specific content (e.g., always focusing on certain markers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in [\"O B A F G\", \"Mercury Venus Earth Mars Jupiter\"]:\n",
    "    A, tokens = attention_for_prompt(prompt, params, d_model, token_to_id, id_to_token)\n",
    "    plot_attention(A, tokens, title=f\"Attention for: {prompt}\")\n",
    "# Write your observations in a markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. The \"Move\" Part (OV) — Copying information\n",
    "\n",
    "In attention, **A** decides *where to read*, and **V** carries *what we copy*. To make this concrete,\n",
    "we'll build a **toy V** that is a one-hot of token identity. Then **A @ V** literally copies the identity\n",
    "of the attended token.\n",
    "\n",
    "**Exercise C — OV copy with one-hots**\n",
    "1. Build `V_onehot = I[vocab][ids]` (shape `(T, V)`).\n",
    "2. Compute `Y_copy = A @ V_onehot`.\n",
    "3. For each row, pick `argmax` to see the copied identity and print the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"O B A F G K M O B A F\"\n",
    "ids = encode(prompt, token_to_id, add_bos=False, add_eos=False)\n",
    "T = len(ids)\n",
    "A, tokens = attention_for_prompt(prompt, params, d_model, token_to_id, id_to_token)\n",
    "\n",
    "# TODO-C1: Implement the OV toy copy using one-hot values\n",
    "# ----- YOUR CODE -----\n",
    "# V_onehot = ...\n",
    "# Y_copy   = ...\n",
    "# pred_ids = ...\n",
    "# pred_tokens = ...\n",
    "raise NotImplementedError(\"TODO-C1: OV copy (A @ one-hot V)\")\n",
    "\n",
    "# Expected behavior: If row i attends to column j, the predicted token for row i should be tokens[j]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Greedy Generation (qualitative check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens, params, token_to_id, id_to_token, d_model, T_ctx=16):\n",
    "    ids = encode(prompt, token_to_id, add_bos=False, add_eos=False)\n",
    "    ids = ids.tolist()\n",
    "    for _ in range(max_new_tokens):\n",
    "        x_ids = np.array(ids[-T_ctx:], dtype=np.int64) if len(ids) >= T_ctx else np.array(ids, dtype=np.int64)\n",
    "        logits, _ = forward_sequence(x_ids, params, d_model)\n",
    "        next_id = int(np.argmax(logits[-1]))\n",
    "        ids.append(next_id)\n",
    "    return decode(np.array(ids, dtype=np.int64), id_to_token)\n",
    "\n",
    "print(\"After training, try a few continuations:\")\n",
    "print(\"Spectral:\", generate(\"O B A\", 8, params, token_to_id, id_to_token, d_model))\n",
    "print(\"Planets :\", generate(\"Mercury Venus Earth\", 8, params, token_to_id, id_to_token, d_model))\n",
    "print(\"Fact    :\", generate(\"The Sun is a\", 6, params, token_to_id, id_to_token, d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c62a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
